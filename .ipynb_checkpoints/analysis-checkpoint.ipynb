{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import math\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint as pp\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# import ipdb; ipdb.set_trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/steve-mar-2021.csv\", sep=';', index_col=0, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='Time', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[1:,:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerpoints_1=df.loc[:, \"Power1\"]\n",
    "powerpoints_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_function(x):\n",
    "    if type(x) == str:\n",
    "        return 0\n",
    "    else:\n",
    "        return int(round(float(x),0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes invalid data and converts everything to whole number-rounded ints\n",
    "def process_row(series: pd.Series) -> pd.Series:\n",
    "#     series = pd.Series([int(round(float(row),0)) for row in series.tolist()])\n",
    "#     series = series.replace(r'\\'-?\\w', '0', regex=True)\n",
    "    series1 = pd.Series([0 if str(row).startswith(\"'\") else row for row in series])\n",
    "#     [print(row) for row in series if str(row).startswith(\"'\")]\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "#     m = series.apply(lambda x: x[0].startswith(\"'\"))\n",
    "#     print(series[m])\n",
    "#     [print(i) for i in series[m]]\n",
    "    series1 = series1.apply(lambda row: int(round(float(row),0)))\n",
    "    series1.index = series.index\n",
    "#     series = series.apply(filter_function)\n",
    "#     for index, row in series.iteritems():\n",
    "#         if type(row) is str: \n",
    "#             if (row[0] == \"'\"):\n",
    "#                 try:\n",
    "#                     # if this throws an IndexError, the row is invalid\n",
    "#                     second_digit = row[2]\n",
    "\n",
    "#                     # remove ' \n",
    "#                     series[index] = row[1:]            \n",
    "#                 except IndexError:\n",
    "#                     # delete invalid row\n",
    "#                     del(series[index])\n",
    "#                     continue\n",
    "\n",
    "        # convert to ints rounded to nearest whole number\n",
    "#         series[index] = int(round(float(row),0))\n",
    "    return series1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerpoints_1 = process_row(powerpoints_1)\n",
    "powerpoints_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a tuple of shape (closest_index, closest_value),\n",
    "# which contains the closest value to the given value in the given array\n",
    "def get_nearest(arr: List[int], value: int) -> Tuple[int, int]:\n",
    "    closest = sys.maxsize\n",
    "    closest_index = sys.maxsize\n",
    "    for index, i in enumerate(arr):\n",
    "        if (abs(value-i) < abs(value-closest)):\n",
    "            closest = i\n",
    "            closest_index = index\n",
    "    \n",
    "    return closest_index, closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an ordered series where the indexes are power values and the first values are the frequencies.\n",
    "# The first element in the series is the most frequent \n",
    "def get_frequencies(freqs: pd.Series, series: pd.Series) -> pd.Series:\n",
    "#     freqs = cleaned_data.value_counts()\n",
    "    new_values = []\n",
    "    new_freqs = []\n",
    "    i = 1\n",
    "    j = 0\n",
    "\n",
    "    # initialise lists to contain first item in the value_counts()\n",
    "    new_values.append(freqs.iloc[0:0+1].index.values[0])\n",
    "    new_freqs.append(freqs[freqs.iloc[0:0+1].index.values[0]])\n",
    "\n",
    "    for value, freq in freqs.iteritems():\n",
    "        # last item so checking 'next' item will throw IndexError\n",
    "        if (value == series.value_counts().iloc[-1:].index.values[0]):\n",
    "            i+=1\n",
    "            j+=1\n",
    "            continue\n",
    "\n",
    "        current_value = freqs.iloc[j:j+1].index.values[0]\n",
    "        compared_index, compared_value = get_nearest(new_values, current_value)\n",
    "\n",
    "        # basically the same\n",
    "        if (abs(current_value - compared_value) < 8 ):\n",
    "            new_values[compared_index] = (current_value + compared_value) / 2\n",
    "            new_freqs[compared_index] = freqs[current_value] + new_freqs[compared_index]\n",
    "\n",
    "        # not the same so insert new entry \n",
    "        else:\n",
    "            new_values.append(current_value)\n",
    "            new_freqs.append(freqs[current_value])\n",
    "            i+=1\n",
    "        j+=1    \n",
    "\n",
    "\n",
    "    return pd.Series(new_freqs, index=new_values).sort_values(ascending=False)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = powerpoints_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_freqs_count = get_frequencies(freqs, powerpoints_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling this a second time (with the result of the first call passed in) groups the frequencies more tightly\n",
    "second_freqs_count = get_frequencies(first_freqs_count, powerpoints_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_freqs_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the two most frequent power readings of the data.\n",
    "# From this, we can determine the cycling power signals of the refrigerator.\n",
    "def get_modes(data: pd.Series) -> Tuple[int, int]:\n",
    "    \n",
    "    # First mode\n",
    "    value_counts = data.value_counts()\n",
    "    ser = value_counts.index\n",
    "    mode = ser[0]\n",
    "    count = 0\n",
    "    for i in ser:\n",
    "        if (abs(i-mode) < 10):\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    val_total = 0\n",
    "    freq_total = 0\n",
    "    index = 0\n",
    "    while (index < count):\n",
    "        val_total += value_counts.iloc[index] * ser[index]\n",
    "        freq_total += value_counts.iloc[index]\n",
    "        index += 1\n",
    "    mode = int(round((val_total / freq_total), 2))\n",
    "\n",
    "    \n",
    "    # Second mode\n",
    "    i = 0\n",
    "    for index, freq in value_counts.iteritems():\n",
    "        if (not (abs(ser[i] - mode) < 10)):\n",
    "            second_mode = ser[i]\n",
    "            break\n",
    "        i+=1\n",
    "\n",
    "    return mode, second_mode\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_modes(powerpoints_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return True if the peak value (less the peak start value) is within the range specified (less the peak start value)\n",
    "def isInRange(peak_value: int, trough_value: int, min_power: int, max_power: int) -> bool:\n",
    "    if ((peak_value - trough_value >= min_power) and\n",
    "        (peak_value - trough_value <= max_power)):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a series of tuples of shape: (peak_start_time, peak_max_value, peak_duration),\n",
    "# where each peak is within the range specified, finishes within the specified duration, and \n",
    "# is off for at least off_requirement minutes after the peak\n",
    "def get_peaks(data: pd.Series, min_power: int, max_power: int, min_required_duration: int = 0, max_required_duration: int = sys.maxsize, off_requirement: int = 0) -> List[Tuple[str, int, int]]:\n",
    "    i = 5\n",
    "    peaks = []\n",
    "    \n",
    "    while i < len(data):\n",
    "#         if (i == 3916):\n",
    "#             import ipdb; ipdb.set_trace()\n",
    "\n",
    "        peak_duration = 2 # +1 for the initial turning on, +1 for turning off\n",
    "        try:\n",
    "            curr_idx = i\n",
    "            prev_idx = i-1\n",
    "            next_idx = i+1\n",
    "            climb_start_idx = 0\n",
    "            peak_idx = 0\n",
    "            if (data.iloc[curr_idx] - data.iloc[prev_idx] > 50): # could be the start of a peak\n",
    "                climb_start_idx = prev_idx # mark start of climb...\n",
    "                peak_idx = curr_idx\n",
    "                while(True):\n",
    "                    curr_off_duration = off_requirement\n",
    "                    if (data.iloc[next_idx] - data.iloc[curr_idx] > 10): # still rising... not at peak yet\n",
    "                        curr_idx+=1\n",
    "                        prev_idx+=1\n",
    "                        next_idx+=1\n",
    "                        if (data.iloc[curr_idx] > data.iloc[peak_idx]):\n",
    "                            peak_idx=curr_idx\n",
    "                        peak_duration+=1\n",
    "                    elif (abs(data.iloc[next_idx] - data.iloc[curr_idx]) < 10): # not rising but still at the same peak\n",
    "                        curr_idx+=1\n",
    "                        prev_idx+=1\n",
    "                        next_idx+=1\n",
    "                        peak_duration+=1\n",
    "                    elif (data.iloc[next_idx] > data.iloc[climb_start_idx] + 150): # not at (close enough to) being a trough yet\n",
    "                        curr_idx+=1\n",
    "                        prev_idx+=1\n",
    "                        next_idx+=1\n",
    "                        peak_duration+=1\n",
    "                    else: # at a trough, so append climb_start which is the initial peak\n",
    "                        if (peak_duration <= max_required_duration and \n",
    "                            isInRange(data.iloc[peak_idx], data.iloc[climb_start_idx], min_power, max_power)):\n",
    "                            satisfied_off_requirement = True\n",
    "                            while (curr_off_duration > 0):\n",
    "                                if (data.iloc[next_idx+1] > data.iloc[next_idx] + 100): # hasn't been a trough for long enough\n",
    "                                    satisfied_off_requirement = False\n",
    "                                    break\n",
    "                                curr_off_duration -= 1\n",
    "                                curr_idx+=1\n",
    "                                prev_idx+=1\n",
    "                                next_idx+=1\n",
    "                            if (not satisfied_off_requirement):\n",
    "                                curr_idx = next_idx\n",
    "                                prev_idx = curr_idx-1\n",
    "                                next_idx+=1\n",
    "                                continue\n",
    "                            if (not peak_duration < min_required_duration):\n",
    "                                peaks.append((data.index[climb_start_idx], data.iloc[peak_idx] - data.iloc[climb_start_idx], peak_duration))\n",
    "                        break\n",
    "            i = next_idx\n",
    "        except IndexError:\n",
    "            i = next_idx\n",
    "    \n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "food_prep_peaks = get_peaks(powerpoints_1, 700, 2200, 0, 10, 0)\n",
    "print(len(food_prep_peaks))\n",
    "pp.pprint(food_prep_peaks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfs01a_microwave_peaks = get_peaks(powerpoints_1, 600, 1200, 0, 10, 0)\n",
    "print(len(hfs01a_microwave_peaks))\n",
    "pp.pprint(hfs01a_microwave_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stovetop peaks\n",
    "stove=df.loc[:, \"Oven\"]\n",
    "stove = process_row(stove)\n",
    "stove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfs01a_stove_peaks = get_peaks(stove, 500, 5000, 0, 120, 60)\n",
    "print(len(hfs01a_stove_peaks))\n",
    "pp.pprint(hfs01a_stove_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lights=df.loc[:, \"Lights2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lights = process_row(lights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_modes(lights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns True if the value is between the start and end times\n",
    "def timeInRange(value: str, start: str, end: str, days_overlap: bool) -> bool:\n",
    "    midnight_mins = 1440\n",
    "    \n",
    "    # get all strings into int's representing total minutes\n",
    "    value_mins = (int(value[0:2]) * 60) + int(value[3:5])\n",
    "    start_mins = (int(start[0:2]) * 60) + int(start[3:5])\n",
    "    end_mins = (int(end[0:2]) * 60) + int(end[3:5])\n",
    "     \n",
    "    # if the end time is in the early hours of the next day, alter the value time and end time by adding 24hours  \n",
    "    if (days_overlap):\n",
    "        end_mins += 24 * 60\n",
    "        if not (midnight_mins - value_mins < midnight_mins - start_mins):\n",
    "            value_mins += (24 * 60)\n",
    "    \n",
    "    if (value_mins <= end_mins and value_mins >= start_mins):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the average time in the given data as a formatted string\n",
    "def get_average_wake_or_sleep(data: List[Tuple[str, str, int]], overnight_cases: bool = False) -> str:\n",
    "    total_mins = 0\n",
    "    for row in data:\n",
    "        row_mins = (int(row[0][11:13]) * 60) + int(row[0][14:16])\n",
    "        \n",
    "        if (overnight_cases and row_mins <= 120):\n",
    "            row_mins += (24 * 60)\n",
    "        total_mins += row_mins\n",
    "    \n",
    "    hours = (total_mins / (len(data) * 60)) % 24\n",
    "    hours = int(math.floor(hours))\n",
    "    mins = total_mins % 60\n",
    "     \n",
    "    dt = datetime.datetime(2000, 1, 1, hours, mins, 0)\n",
    "    \n",
    "    return dt.strftime(\"%X\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the most common sleep time and wake time (i.e. circadian rythm)\n",
    "# TODO: Ignore weekends for a more accurate result\n",
    "def get_circadian_rythm(data: pd.Series) -> Tuple[str, str]:\n",
    "    i = 0\n",
    "    res = []\n",
    "    on_cases = []\n",
    "    off_cases = []\n",
    "    resting_power = get_modes(data)[0]\n",
    "    while i < len(data):\n",
    "        try:\n",
    "            on_duration = 0\n",
    "            off_duration = 0\n",
    "            while (data.iloc[i] > resting_power): # lights are on\n",
    "                on_duration += 1\n",
    "                i+=1\n",
    "            \n",
    "            if on_duration > 120 and timeInRange(data.index[i][11:], '19:00:00', '02:00:00', True): # lights have been on for more than 100 minutes\n",
    "                off_cases.append((data.index[i], 'turning off', on_duration))\n",
    "\n",
    "            while (data.iloc[i] <= resting_power): # lights are off\n",
    "                off_duration += 1\n",
    "                i+=1\n",
    "                \n",
    "            if off_duration > 120 and timeInRange(data.index[i][11:], '03:00:00', '10:00:00', False): # lights have been off for more than 100 minutes\n",
    "                on_cases.append((data.index[i], 'turning on', off_duration))\n",
    "\n",
    "            i+=1\n",
    "        \n",
    "        except IndexError:\n",
    "            i+=1\n",
    "            \n",
    "    average_wake = get_average_wake_or_sleep(on_cases)\n",
    "    average_sleep = get_average_wake_or_sleep(off_cases, True)\n",
    "    \n",
    "    return (average_wake, average_sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the most common left the house and got home from work (i.e. work schedule)\n",
    "# TODO: Ignore weekends for a more accurate result\n",
    "def get_work_schedule(data: pd.Series) -> Tuple[str, str]:\n",
    "    i = 0\n",
    "    res = []\n",
    "    on_cases = []\n",
    "    off_cases = []\n",
    "    resting_power = get_modes(data)[0]\n",
    "    while i < len(data):\n",
    "        try:\n",
    "            on_duration = 0\n",
    "            off_duration = 0\n",
    "            while (data.iloc[i] > resting_power): # lights are on\n",
    "                on_duration += 1\n",
    "                i+=1\n",
    "            \n",
    "            if on_duration > 120 and timeInRange(data.index[i][11:], '05:00:00', '10:00:00', False): # lights have been on for more than 100 minutes\n",
    "                off_cases.append((data.index[i], 'turning off', on_duration))\n",
    "\n",
    "            while (data.iloc[i] <= resting_power): # lights are off\n",
    "                off_duration += 1\n",
    "                i+=1\n",
    "                \n",
    "            if off_duration > 120 and timeInRange(data.index[i][11:], '14:00:00', '19:00:00', False): # lights have been off for more than 100 minutes\n",
    "                on_cases.append((data.index[i], 'turning on', off_duration))\n",
    "\n",
    "            i+=1\n",
    "        \n",
    "        except IndexError:\n",
    "            i+=1\n",
    "            \n",
    "    average_home = get_average_wake_or_sleep(on_cases)\n",
    "    average_leave = get_average_wake_or_sleep(off_cases, True)\n",
    "    \n",
    "    return (average_leave, average_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circadian_rythm = get_circadian_rythm(lights)\n",
    "circadian_rythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aircon = df.loc[:, \"Aircon1\"]\n",
    "aircon = process_row(aircon)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aircon_peaks = get_peaks(aircon, 100, 10000, 10, 1000, 60)\n",
    "print(len(aircon_peaks))\n",
    "pp.pprint(aircon_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the energy usage (Wh) of each peak\n",
    "def get_watt_hours(peaks: List[Tuple[str,int,int]], data: pd.Series) -> List[Tuple[str,int]]:\n",
    "    watt_hours = []\n",
    "    for peak in peaks:\n",
    "        watt_hour = 0\n",
    "        for _ in range(peak[2]):\n",
    "            watt_hour += data.loc[peak[0]]\n",
    "        watt_hours.append((peak[0], watt_hour))\n",
    "\n",
    "    return watt_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watt_hours = get_watt_hours(aircon_peaks, aircon)\n",
    "watt_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_usage(arr: List[Tuple[str,int]]) -> pd.Series:\n",
    "    df = pd.DataFrame(arr).set_index(0)[1]\n",
    "    df.index.name = 'Time'\n",
    "    df.name = 'Processed Watt Hours'\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.resample('D').sum()\n",
    "    \n",
    "    start_date = int(df.index[0].strftime(\"%d\"))\n",
    "    i = start_date - 1\n",
    "    while (i > 0):\n",
    "        datetime = pd.Timestamp(int(df.index[0].strftime(\"%Y\")), int(df.index[0].strftime(\"%m\")), i, 0, 0, 0)\n",
    "        df.loc[datetime] = 0\n",
    "        df.sort_index(inplace=True) \n",
    "        i-=1\n",
    "    \n",
    "    end_date = int(df.index[-1].strftime(\"%d\"))\n",
    "    i = end_date + 1\n",
    "    from calendar import monthrange\n",
    "    days_in_month = monthrange(int(df.index[-1].strftime(\"%Y\")), int(df.index[-1].strftime(\"%m\")))[1]\n",
    "    while (i <= days_in_month):\n",
    "        datetime = pd.Timestamp(int(df.index[-1].strftime(\"%Y\")), int(df.index[-1].strftime(\"%m\")), i, 0, 0, 0)\n",
    "        df.loc[datetime] = 0\n",
    "        df.sort_index(inplace=True) \n",
    "        i+=1\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_series = get_daily_usage(watt_hours)\n",
    "usage_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bom_data(filename: str, isHigh: bool) -> List[int]:\n",
    "    data = pd.read_csv(filename, sep=',', index_col=0, dtype=object)\n",
    "    data_col = data.iloc[:, 1] if isHigh else data.iloc[:, 0]\n",
    "    temps = [int(float(data_col.iloc[i])) for i in range(len(data_col))]\n",
    "    \n",
    "    return temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mar_2021 = load_bom_data(\"data/extra/bom-mar-2021.csv\", True)\n",
    "\n",
    "dec_2020 = load_bom_data(\"data/extra/bom-dec-2020.csv\", True)\n",
    "jan_2021 = load_bom_data(\"data/extra/bom-jan-2021.csv\", True)\n",
    "feb_2021 = load_bom_data(\"data/extra/bom-feb-2021.csv\", True)\n",
    "max_temps_summer = dec_2020 + jan_2021 + feb_2021\n",
    "\n",
    "jun_2020 = load_bom_data(\"data/extra/bom-jun-2020.csv\", False)\n",
    "jul_2020 = load_bom_data(\"data/extra/bom-jul-2020.csv\", False)\n",
    "aug_2020 = load_bom_data(\"data/extra/bom-aug-2020.csv\", False)\n",
    "min_temps_winter = jun_2020 + jul_2020 + aug_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/uq49_01-06-2020--31-08-2020.csv\", sep=';', index_col=0, dtype=object)\n",
    "df = df.sort_values(by='Time', ascending=True)\n",
    "df = df.iloc[1:,:]\n",
    "\n",
    "df1 = pd.read_csv(\"data/uq49_01-12-2020--28-02-2021.csv\", sep=';', index_col=0, dtype=object)\n",
    "df1 = df1.sort_values(by='Time', ascending=True)\n",
    "df1 = df1.iloc[1:,:]\n",
    "\n",
    "df2 = pd.read_csv(\"data/uq49_01-12-2020--31-12-2020.csv\", sep=';', index_col=0, dtype=object)\n",
    "df2 = df2.sort_values(by='Time', ascending=True)\n",
    "df2 = df2.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerpoints_uq49 = df2.loc[:, \"Powerpoints1\"]\n",
    "powerpoints_uq49 = process_row(powerpoints_uq49)\n",
    "\n",
    "hob_uq49 = df2.loc[:, \"Hob\"]\n",
    "hob_uq49 = process_row(hob_uq49)\n",
    "\n",
    "microwave_peaks_uq49 = get_peaks(powerpoints_uq49, 600, 1200, 0, 10, 0)\n",
    "print(len(microwave_peaks_uq49))\n",
    "pp.pprint(microwave_peaks_uq49)\n",
    "\n",
    "stove_peaks_uq49 = get_peaks(hob_uq49, 500, 5000, 0, 120, 60)\n",
    "print(len(stove_peaks_uq49))\n",
    "pp.pprint(stove_peaks_uq49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aircon_winter = df.loc[:, \"Aircon1\"]\n",
    "aircon_winter = process_row(aircon_winter)\n",
    "\n",
    "aircon_summer = df1.loc[:, \"Aircon1\"]\n",
    "aircon_summer = process_row(aircon_summer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aircon_winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aircon_summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aircon_peaks_winter = get_peaks(aircon_winter, 100, 10000, 0, 1000, 60)\n",
    "aircon_peaks_winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aircon_peaks_summer = get_peaks(aircon_summer, 100, 10000, 0, 1000, 60)\n",
    "aircon_peaks_summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watt_hours_winter = get_watt_hours(aircon_peaks_winter, aircon_winter)\n",
    "watt_hours_winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watt_hours_summer = get_watt_hours(aircon_peaks_summer, aircon_summer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_series_winter = get_daily_usage(watt_hours_winter)\n",
    "usage_series_winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_series_summer = get_daily_usage(watt_hours_summer)\n",
    "usage_series_summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Consider using another metric for heat sensitivity\n",
    "def plot_aircon_trend(usage_series: pd.Series, temps: List[int], s_type: str):\n",
    "    usage = usage_series.tolist()\n",
    "    x_ticks = [i for i in range(len(usage)) if i % 4 == 0]\n",
    "    x_ticklabels = [usage_series.index[i].strftime(\"%Y/%m/%d\") for i in x_ticks]\n",
    "\n",
    "    n=len(usage)\n",
    "    position = np.arange(n)\n",
    "    offset = 0.15\n",
    "    width = 0.3\n",
    "\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax2 = ax.twinx()\n",
    "\n",
    "    ax.bar(position - offset, temps, width, label = s_type + \" Temperature\", color='orange')\n",
    "    ax2.bar(position + offset, usage, width, label = 'Aircon Usage', color='blue')\n",
    "    \n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc=0)\n",
    "    \n",
    "    min_temp = min(temps)\n",
    "    max_temp = max(temps)\n",
    "\n",
    "    ax2.set_ylabel(\"Power W\")\n",
    "    ax.set_ylabel(\"Degree's C\")\n",
    "    ax.set_ylim([min_temp-2,max_temp+2])\n",
    "\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels(x_ticklabels, rotation=60)\n",
    "    \n",
    "    plt.title(s_type + \" Temperature vs. Aircon Usage\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_aircon_trend(usage_series, mar_2021, s_type=\"Max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_aircon_trend(usage_series_winter, min_temps_winter, s_type=\"Min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_aircon_trend(usage_series_summer, max_temps_summer, s_type=\"Max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabilities(temps: List[int], usage_series: pd.Series):\n",
    "    usage = usage_series.tolist()\n",
    "    \n",
    "    td = pd.DataFrame(temps)\n",
    "    td = [int(float(td.iloc[i])) for i in range(len(td))]\n",
    "    td = pd.Series(td)\n",
    "\n",
    "    n = pd.DataFrame()\n",
    "    n['temps'] = td\n",
    "    n['vals'] = usage\n",
    "    \n",
    "    num_days = len(temps)\n",
    "    \n",
    "    probs = []\n",
    "    min_temp = min(temps)\n",
    "    max_temp = max(temps)\n",
    "    \n",
    "    # Bayes' Theorem\n",
    "    for i in range(min_temp, max_temp+1):\n",
    "        p_a = usage_series.gt(0).sum() / num_days\n",
    "        p_b = td.eq(i).sum() / num_days\n",
    "        p_a_or_b = (n['vals'].gt(0) | n['temps'].eq(i)).sum() / num_days\n",
    "        p_a_and_b = p_a + p_b - p_a_or_b\n",
    "        if (p_b == 0):\n",
    "            probs.append(np.nan)\n",
    "            continue\n",
    "        p_a_given_b = p_a_and_b / p_b\n",
    "        probs.append(round(p_a_given_b,2))\n",
    "    \n",
    "    return probs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_probabilities(mar_2021, usage_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probability_curve(temps: List[int], usage_series: pd.Series):\n",
    "        \n",
    "    min_temp = min(temps)\n",
    "    max_temp = max(temps)\n",
    "        \n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "        \n",
    "    probs = get_probabilities(temps, usage_series)\n",
    "    interpolated = pd.Series(probs).interpolate().values.ravel().tolist()\n",
    "    \n",
    "    y = probs\n",
    "    y = np.array(y)\n",
    "    x = np.arange(min_temp, max_temp+1, 1)\n",
    "        \n",
    "    plt.plot(x, interpolated)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim([0.0,1.0])\n",
    "    \n",
    "    plt.xlabel(\"Temperature (C)\")\n",
    "    plt.ylabel(\"Probability of Aircon Use\")\n",
    "    plt.title(\"Probability Curve of Aircon Usage vs Temperature\")\n",
    "    plt.show()\n",
    "    \n",
    "    return x, interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_probability_curve(mar_2021, usage_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_probability_curve(max_temps_summer, usage_series_summer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_probability_curve(min_temps_winter, usage_series_winter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probs_combined(min_temps_winter: List[int], usage_series_winter: pd.Series, max_temps_summer: List[int], usage_series_summer: pd.Series):\n",
    "    winter_probs = get_probabilities(min_temps_winter, usage_series_winter)\n",
    "    summer_probs = get_probabilities(max_temps_summer, usage_series_summer)\n",
    "    \n",
    "    all_temps = np.arange(min(min_temps_winter), max(max_temps_summer)+1, 1)\n",
    "    all_probs = [0.0] * len(all_temps)\n",
    "    \n",
    "    i=0\n",
    "    while (i < len(winter_probs)):\n",
    "        all_probs[i] = winter_probs[i]\n",
    "        i+=1\n",
    "\n",
    "    j = len(all_probs) - len(summer_probs)\n",
    "    while (j < len(all_probs)):\n",
    "        all_probs[j] = summer_probs[j-len(summer_probs)-1]\n",
    "        j+=1\n",
    "        \n",
    "    interpolated = pd.Series(all_probs).interpolate().values.ravel().tolist()\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    plt.plot(all_temps, interpolated)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim([0.0,1.0])\n",
    "\n",
    "    plt.xlabel(\"Temperature (C)\")\n",
    "    plt.ylabel(\"Probability of Aircon Use\")\n",
    "    plt.title(\"Probability Curve of Aircon Usage vs Temperature\")\n",
    "    plt.show()\n",
    "    \n",
    "    return all_temps, all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Maybe filter this so that only major aircon usages are plotted.\n",
    "plot_probs_combined(min_temps_winter, usage_series_winter, max_temps_summer, usage_series_summer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Microwave vs Stovetop Visualisation\n",
    "\n",
    "#  1. Get access to PhiSaver API\n",
    "#  2. Get average of all households' microwave use AND stovetop use\n",
    "#  3. ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATABASE INTERACTIONS START HERE ---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from influxdb import InfluxDBClient, DataFrameClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "client2 = InfluxDBClient(host='live2.phisaver.com', database='phisaver', username='reader', password='Rmagine!', port=8086, headers={'Accept': 'application/json'}, gzip=True)\n",
    "# q = \"\"\"SELECT * FROM \"iotawatt\" WHERE \"device\" = 'hfs01a' AND \"time\" > '2021-05-31T11:58:20Z' - 12w\"\"\"\n",
    "\n",
    "# client_df = pd.DataFrame(client2.query(q, chunked=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_circuits = { \\\n",
    "                  \"uq10\": \"Powerpoints1\",\n",
    "                  \"uq12\": \"Powerpoints2\",\n",
    "                  \"uq23\": \"Powerpoints1\",\n",
    "                  \"uq24\": \"Powerpoints2\",\n",
    "                  \"uq26\": \"Powerpoints1\",\n",
    "                  \"hfs01a\": \"Power1\"\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stove_circuits = { \\\n",
    "                  \"uq10\": \"Oven\",\n",
    "                  \"uq12\": \"Stove\",\n",
    "                  \"uq23\": \"Stove\",\n",
    "                  \"uq24\": \"OvenHob\",\n",
    "                  \"uq26\": \"Stove\",\n",
    "                  \"hfs01a\": \"Hotplate\"\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average (or similar) and bounds for microwave and stovetop usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_in_period(client, start_date, end_date, device, sensor):\n",
    "    current_date = start_date\n",
    "    dataF = pd.DataFrame()\n",
    "    \n",
    "    while (current_date < end_date):\n",
    "        q = \"\"\"SELECT * FROM \"iotawatt\" WHERE \"device\" = {} AND \"sensor\" = {} AND \"time\" >= {} AND \"time\" <= {}\"\"\".format(device, sensor, current_date, end_date)\n",
    "#         print(q)\n",
    "        data = pd.DataFrame(client.query(q, chunked=True))\n",
    "        dataF = dataF.append(data, ignore_index=True)\n",
    "        most_recent_time = get_most_recent_time(dataF)\n",
    "        current_date = most_recent_time\n",
    "    \n",
    "    return dataF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_recent_time(df):\n",
    "    last_idx = df.index[-1]-1\n",
    "    last_arr = df[0][last_idx]\n",
    "    last_time = last_arr[-1].get(\"time\")\n",
    "    return \"'{}'\".format(last_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'2021-03-01T00:00:00Z'\n",
      "'2021-03-31T23:59:50Z'\n",
      "SELECT * FROM \"iotawatt\" WHERE \"device\" = 'uq10' AND \"sensor\" = 'Powerpoints1' AND \"time\" >= '2021-03-01T00:00:00Z' AND \"time\" <= '2021-03-31T23:59:50Z'\n",
      "                                                    0\n",
      "0   [{'time': '2021-03-01T00:00:00Z', 'PF': None, ...\n",
      "1   [{'time': '2021-03-02T03:46:40Z', 'PF': None, ...\n",
      "2   [{'time': '2021-03-03T07:33:20Z', 'PF': None, ...\n",
      "3   [{'time': '2021-03-04T11:20:00Z', 'PF': None, ...\n",
      "4   [{'time': '2021-03-05T15:06:40Z', 'PF': None, ...\n",
      "5   [{'time': '2021-03-06T18:53:20Z', 'PF': None, ...\n",
      "6   [{'time': '2021-03-07T22:40:00Z', 'PF': None, ...\n",
      "7   [{'time': '2021-03-09T02:26:40Z', 'PF': None, ...\n",
      "8   [{'time': '2021-03-10T06:13:20Z', 'PF': None, ...\n",
      "9   [{'time': '2021-03-11T10:00:00Z', 'PF': None, ...\n",
      "10  [{'time': '2021-03-12T13:50:20Z', 'PF': None, ...\n",
      "11  [{'time': '2021-03-13T17:37:00Z', 'PF': None, ...\n",
      "12  [{'time': '2021-03-14T21:23:40Z', 'PF': None, ...\n",
      "13  [{'time': '2021-03-16T01:10:20Z', 'PF': None, ...\n",
      "14  [{'time': '2021-03-17T04:57:00Z', 'PF': None, ...\n",
      "15  [{'time': '2021-03-18T08:43:40Z', 'PF': None, ...\n",
      "16  [{'time': '2021-03-19T12:30:20Z', 'PF': None, ...\n",
      "17  [{'time': '2021-03-20T16:17:00Z', 'PF': None, ...\n",
      "18  [{'time': '2021-03-21T20:03:40Z', 'PF': None, ...\n",
      "19  [{'time': '2021-03-22T23:50:20Z', 'PF': None, ...\n",
      "20  [{'time': '2021-03-24T03:49:10Z', 'PF': None, ...\n",
      "21  [{'time': '2021-03-25T07:36:00Z', 'PF': None, ...\n",
      "22  [{'time': '2021-03-26T11:22:40Z', 'PF': None, ...\n",
      "23  [{'time': '2021-03-27T15:09:20Z', 'PF': None, ...\n",
      "24  [{'time': '2021-03-28T18:56:00Z', 'PF': None, ...\n",
      "25  [{'time': '2021-03-29T22:42:40Z', 'PF': None, ...\n",
      "26  [{'time': '2021-03-31T02:29:20Z', 'PF': None, ...\n",
      "SELECT * FROM \"iotawatt\" WHERE \"device\" = 'uq10' AND \"sensor\" = 'Powerpoints1' AND \"time\" >= '2021-03-31T02:29:10Z' AND \"time\" <= '2021-03-31T23:59:50Z'\n",
      "                                                    0\n",
      "0   [{'time': '2021-03-01T00:00:00Z', 'PF': None, ...\n",
      "1   [{'time': '2021-03-02T03:46:40Z', 'PF': None, ...\n",
      "2   [{'time': '2021-03-03T07:33:20Z', 'PF': None, ...\n",
      "3   [{'time': '2021-03-04T11:20:00Z', 'PF': None, ...\n",
      "4   [{'time': '2021-03-05T15:06:40Z', 'PF': None, ...\n",
      "5   [{'time': '2021-03-06T18:53:20Z', 'PF': None, ...\n",
      "6   [{'time': '2021-03-07T22:40:00Z', 'PF': None, ...\n",
      "7   [{'time': '2021-03-09T02:26:40Z', 'PF': None, ...\n",
      "8   [{'time': '2021-03-10T06:13:20Z', 'PF': None, ...\n",
      "9   [{'time': '2021-03-11T10:00:00Z', 'PF': None, ...\n",
      "10  [{'time': '2021-03-12T13:50:20Z', 'PF': None, ...\n",
      "11  [{'time': '2021-03-13T17:37:00Z', 'PF': None, ...\n",
      "12  [{'time': '2021-03-14T21:23:40Z', 'PF': None, ...\n",
      "13  [{'time': '2021-03-16T01:10:20Z', 'PF': None, ...\n",
      "14  [{'time': '2021-03-17T04:57:00Z', 'PF': None, ...\n",
      "15  [{'time': '2021-03-18T08:43:40Z', 'PF': None, ...\n",
      "16  [{'time': '2021-03-19T12:30:20Z', 'PF': None, ...\n",
      "17  [{'time': '2021-03-20T16:17:00Z', 'PF': None, ...\n",
      "18  [{'time': '2021-03-21T20:03:40Z', 'PF': None, ...\n",
      "19  [{'time': '2021-03-22T23:50:20Z', 'PF': None, ...\n",
      "20  [{'time': '2021-03-24T03:49:10Z', 'PF': None, ...\n",
      "21  [{'time': '2021-03-25T07:36:00Z', 'PF': None, ...\n",
      "22  [{'time': '2021-03-26T11:22:40Z', 'PF': None, ...\n",
      "23  [{'time': '2021-03-27T15:09:20Z', 'PF': None, ...\n",
      "24  [{'time': '2021-03-28T18:56:00Z', 'PF': None, ...\n",
      "25  [{'time': '2021-03-29T22:42:40Z', 'PF': None, ...\n",
      "26  [{'time': '2021-03-31T02:29:20Z', 'PF': None, ...\n",
      "27  [{'time': '2021-03-31T02:29:10Z', 'PF': None, ...\n",
      "'2021-03-01T00:00:00Z'\n",
      "'2021-03-31T23:59:50Z'\n",
      "SELECT * FROM \"iotawatt\" WHERE \"device\" = 'uq12' AND \"sensor\" = 'Powerpoints2' AND \"time\" >= '2021-03-01T00:00:00Z' AND \"time\" <= '2021-03-31T23:59:50Z'\n",
      "                                                    0\n",
      "0   [{'time': '2021-03-01T00:00:00Z', 'PF': None, ...\n",
      "1   [{'time': '2021-03-02T03:46:40Z', 'PF': None, ...\n",
      "2   [{'time': '2021-03-03T07:33:20Z', 'PF': None, ...\n",
      "3   [{'time': '2021-03-04T11:20:00Z', 'PF': None, ...\n",
      "4   [{'time': '2021-03-05T15:06:40Z', 'PF': None, ...\n",
      "5   [{'time': '2021-03-06T18:53:20Z', 'PF': None, ...\n",
      "6   [{'time': '2021-03-07T22:40:00Z', 'PF': None, ...\n",
      "7   [{'time': '2021-03-09T02:26:40Z', 'PF': None, ...\n",
      "8   [{'time': '2021-03-10T06:13:20Z', 'PF': None, ...\n",
      "9   [{'time': '2021-03-11T10:00:00Z', 'PF': None, ...\n",
      "10  [{'time': '2021-03-12T13:46:40Z', 'PF': None, ...\n",
      "11  [{'time': '2021-03-13T17:33:20Z', 'PF': None, ...\n",
      "12  [{'time': '2021-03-14T21:20:00Z', 'PF': None, ...\n",
      "13  [{'time': '2021-03-16T01:06:40Z', 'PF': None, ...\n",
      "14  [{'time': '2021-03-17T04:53:20Z', 'PF': None, ...\n",
      "15  [{'time': '2021-03-18T08:40:00Z', 'PF': None, ...\n",
      "16  [{'time': '2021-03-19T12:26:40Z', 'PF': None, ...\n",
      "17  [{'time': '2021-03-20T16:13:20Z', 'PF': None, ...\n",
      "18  [{'time': '2021-03-21T20:00:00Z', 'PF': None, ...\n",
      "19  [{'time': '2021-03-22T23:46:40Z', 'PF': None, ...\n",
      "20  [{'time': '2021-03-24T03:33:20Z', 'PF': None, ...\n",
      "21  [{'time': '2021-03-25T07:20:00Z', 'PF': None, ...\n",
      "22  [{'time': '2021-03-26T11:06:40Z', 'PF': None, ...\n",
      "23  [{'time': '2021-03-27T14:53:20Z', 'PF': None, ...\n",
      "24  [{'time': '2021-03-28T18:40:00Z', 'PF': None, ...\n",
      "25  [{'time': '2021-03-29T22:26:40Z', 'PF': None, ...\n",
      "26  [{'time': '2021-03-31T02:13:20Z', 'PF': None, ...\n",
      "SELECT * FROM \"iotawatt\" WHERE \"device\" = 'uq12' AND \"sensor\" = 'Powerpoints2' AND \"time\" >= '2021-03-31T02:13:10Z' AND \"time\" <= '2021-03-31T23:59:50Z'\n",
      "                                                    0\n",
      "0   [{'time': '2021-03-01T00:00:00Z', 'PF': None, ...\n",
      "1   [{'time': '2021-03-02T03:46:40Z', 'PF': None, ...\n",
      "2   [{'time': '2021-03-03T07:33:20Z', 'PF': None, ...\n",
      "3   [{'time': '2021-03-04T11:20:00Z', 'PF': None, ...\n",
      "4   [{'time': '2021-03-05T15:06:40Z', 'PF': None, ...\n",
      "5   [{'time': '2021-03-06T18:53:20Z', 'PF': None, ...\n",
      "6   [{'time': '2021-03-07T22:40:00Z', 'PF': None, ...\n",
      "7   [{'time': '2021-03-09T02:26:40Z', 'PF': None, ...\n",
      "8   [{'time': '2021-03-10T06:13:20Z', 'PF': None, ...\n",
      "9   [{'time': '2021-03-11T10:00:00Z', 'PF': None, ...\n",
      "10  [{'time': '2021-03-12T13:46:40Z', 'PF': None, ...\n",
      "11  [{'time': '2021-03-13T17:33:20Z', 'PF': None, ...\n",
      "12  [{'time': '2021-03-14T21:20:00Z', 'PF': None, ...\n",
      "13  [{'time': '2021-03-16T01:06:40Z', 'PF': None, ...\n",
      "14  [{'time': '2021-03-17T04:53:20Z', 'PF': None, ...\n",
      "15  [{'time': '2021-03-18T08:40:00Z', 'PF': None, ...\n",
      "16  [{'time': '2021-03-19T12:26:40Z', 'PF': None, ...\n",
      "17  [{'time': '2021-03-20T16:13:20Z', 'PF': None, ...\n",
      "18  [{'time': '2021-03-21T20:00:00Z', 'PF': None, ...\n",
      "19  [{'time': '2021-03-22T23:46:40Z', 'PF': None, ...\n",
      "20  [{'time': '2021-03-24T03:33:20Z', 'PF': None, ...\n",
      "21  [{'time': '2021-03-25T07:20:00Z', 'PF': None, ...\n",
      "22  [{'time': '2021-03-26T11:06:40Z', 'PF': None, ...\n",
      "23  [{'time': '2021-03-27T14:53:20Z', 'PF': None, ...\n",
      "24  [{'time': '2021-03-28T18:40:00Z', 'PF': None, ...\n",
      "25  [{'time': '2021-03-29T22:26:40Z', 'PF': None, ...\n",
      "26  [{'time': '2021-03-31T02:13:20Z', 'PF': None, ...\n",
      "27  [{'time': '2021-03-31T02:13:10Z', 'PF': None, ...\n",
      "'2021-03-01T00:00:00Z'\n",
      "'2021-03-31T23:59:50Z'\n",
      "SELECT * FROM \"iotawatt\" WHERE \"device\" = 'uq23' AND \"sensor\" = 'Powerpoints1' AND \"time\" >= '2021-03-01T00:00:00Z' AND \"time\" <= '2021-03-31T23:59:50Z'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-349613bb90ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmicrowave_dataframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhome\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpower_circuits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmicrowave_dataframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_data_in_period\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"'2021-03-01T00:00:00Z'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"'2021-03-31T23:59:50Z'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"'{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"'{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpower_circuits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-ef499828bd81>\u001b[0m in \u001b[0;36mget_data_in_period\u001b[0;34m(client, start_date, end_date, device, sensor)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\"SELECT * FROM \"iotawatt\" WHERE \"device\" = {} AND \"sensor\" = {} AND \"time\" >= {} AND \"time\" <= {}\"\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mdataF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmost_recent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_most_recent_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    568\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;31m# last ditch effort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;31m# last ditch effort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/influxdb/resultset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;34m\"\"\"Yield one dict instance per series result.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/influxdb/resultset.py\u001b[0m in \u001b[0;36mget_points\u001b[0;34m(self, measurement, tags)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# we will matches every returned series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mseries_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_points_for_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tag_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/influxdb/resultset.py\u001b[0m in \u001b[0;36m_get_points_for_series\u001b[0;34m(self, series)\u001b[0m\n\u001b[1;32m    189\u001b[0m             yield self.point_from_cols_vals(\n\u001b[1;32m    190\u001b[0m                 \u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0mpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             )\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/influxdb/resultset.py\u001b[0m in \u001b[0;36mpoint_from_cols_vals\u001b[0;34m(cols, vals)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[1;32m    202\u001b[0m         \u001b[0mpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcol_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "microwave_dataframes = []\n",
    "for i, home in enumerate(power_circuits):\n",
    "    microwave_dataframes.append(get_data_in_period(client2, \"'2021-03-01T00:00:00Z'\", \"'2021-03-31T23:59:50Z'\", \"'{}'\".format(home), \"'{}'\".format(power_circuits[home])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stove_dataframes = []\n",
    "for i, home in enumerate(stove_circuits):\n",
    "    stove_dataframes.append(get_data_in_period(client2, \"'2020-10-01T00:00:00Z'\", \"'2021-03-31T23:59:50Z'\", \"'{}'\".format(home), \"'{}'\".format(stove_circuits[home])))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now pre-process these df's into the format required for the process() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(dataframes):\n",
    "    post_process = []\n",
    "    if (not isinstance(dataframes, list)):\n",
    "        new_df = []\n",
    "        new_df.append(dataframes)\n",
    "        dataframes = new_df\n",
    "        \n",
    "    for dataframe in dataframes:\n",
    "        df = pd.DataFrame()\n",
    "        for inner_df in dataframe[0]:\n",
    "            to_append = pd.DataFrame(inner_df)\n",
    "            to_append = to_append.set_index('time')\n",
    "            to_append = to_append.loc[:, \"Watts\"]\n",
    "#             to_append = to_append[~to_append.index.duplicated()]\n",
    "            to_append = to_append.to_frame()\n",
    "    \n",
    "            # Filter out the time values that are not on the minute for getting 1-min granularity\n",
    "#             to_append = to_append.groupby(np.arange(len(to_append))//6).mean()\n",
    "#             to_append = to_append.loc[to_append.index.str.endswith('00Z')]\n",
    "            df = df.append(to_append)\n",
    "        \n",
    "        processing = process_row(df.squeeze())\n",
    "        # Granularity filter\n",
    "#         print(\"PPPP: \", processing)\n",
    "#         processing_means = processing.groupby(np.arange(len(processing))//6).sum()\n",
    "#         processing_means.index = processing.index[::6]\n",
    "\n",
    "        post_process.append(processing)\n",
    "        \n",
    "    for df in post_process:\n",
    "        df.index = df.index.to_series().apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ').strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    return post_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(microwave_dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = pre_process(microwave_dataframes)\n",
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stove_processed = pre_process(stove_dataframes)\n",
    "stove_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def microwave_stove_peaks(processed, stove_processed):\n",
    "    microwave = []\n",
    "    stove = []\n",
    "    \n",
    "    for df in processed:\n",
    "        microwave_peaks = get_peaks(df, 600, 1200, 0, 10, 0)\n",
    "        microwave.append(len(microwave_peaks))\n",
    "        \n",
    "    for df in stove_processed:\n",
    "        stove_peaks = get_peaks(df, 500, 5000, 0, 120, 60)\n",
    "        stove.append(len(stove_peaks))\n",
    "        \n",
    "    return microwave, stove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microwave_peaks, stove_peaks = microwave_stove_peaks(processed, stove_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(microwave_peaks)\n",
    "print(stove_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x, x_min, x_max):\n",
    "    return round(2*((x-x_min)/(x_max-x_min))-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uq49_microwave_normalised = normalise(len(microwave_peaks_uq49), min(microwave_peaks), max(microwave_peaks))\n",
    "# uq49_stove_normalised = normalise(len(stove_peaks_uq49), min(stove_peaks), max(stove_peaks))\n",
    "\n",
    "# print(uq49_microwave_normalised)\n",
    "# print(uq49_stove_normalised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hfs01a_microwave_normalised = normalise(len(hfs01a_microwave_peaks), min(microwave_peaks), max(microwave_peaks))\n",
    "# hfs01a_stove_normalised = normalise(len(hfs01a_stove_peaks), min(stove_peaks), max(stove_peaks))\n",
    "\n",
    "# print(hfs01a_microwave_normalised)\n",
    "# print(hfs01a_stove_normalised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# # data={'microwave': hfs01a_microwave_normalised, 'stovetop': hfs01a_stove_normalised}\n",
    "# data={'microwave': uq49_microwave_normalised, 'stovetop': uq49_stove_normalised}\n",
    "\n",
    "# r = requests.post('http://localhost:3001/data', data=data)\n",
    "# print(r.json())\n",
    "# print(r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %history -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_circuits = { \\\n",
    "                  \"uq10\": \"Lights1\",\n",
    "                  \"uq12\": \"Lights12\",\n",
    "                  \"uq23\": \"Lights1\",\n",
    "                  \"uq24\": \"Lights1\",\n",
    "                  \"uq26\": \"Light\",\n",
    "                  \"hfs01a\": \"Lights2\"\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!  Only call this when needing to query DB again  !!!\n",
    "\n",
    "light_dataframes = []\n",
    "for i, home in enumerate(light_circuits):\n",
    "    light_dataframes.append(get_data_in_period(client2, \"'2020-10-01T00:00:00Z'\", \"'2021-03-31T23:59:50Z'\", \"'{}'\".format(home), \"'{}'\".format(light_circuits[home])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(light_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_processed = pre_process(light_dataframes)\n",
    "light_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_circadian_rythm(light_processed):\n",
    "    lst = []\n",
    "    for i in range(len(light_processed)):\n",
    "        try:\n",
    "            lst.append(get_circadian_rythm(light_processed[i]))\n",
    "        except ZeroDivisionError:\n",
    "            print(\"zero div err\")\n",
    "            lst.append(0)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circadian_rythms = get_all_circadian_rythm(light_processed)\n",
    "circadian_rythms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_average_circadian_rythm_time(times):\n",
    "#     total_morning_seconds = 0\n",
    "#     total_night_seconds = 0\n",
    "#     min_morning = '23:59:59'\n",
    "#     max_morning = '00:00:01'\n",
    "#     min_night = '23:59:59'\n",
    "#     max_night = '00:00:01'\n",
    "    \n",
    "#     fmt = \"%H:%M:%S\"\n",
    "    \n",
    "#     for tup in times:\n",
    "#         total_morning_seconds += int(tup[0][6:8])\n",
    "#         total_morning_seconds += int(tup[0][3:5]) * 60\n",
    "#         total_morning_seconds += int(tup[0][0:2]) * 60 * 60\n",
    "        \n",
    "#         total_night_seconds += int(tup[1][6:8])\n",
    "#         total_night_seconds += int(tup[1][3:5]) * 60\n",
    "#         total_night_seconds += int(tup[1][0:2]) * 60 * 60\n",
    "        \n",
    "#         if (datetime.datetime.strptime(tup[0], fmt) < datetime.datetime.strptime(min_morning, fmt)):\n",
    "#             min_morning = tup[0]\n",
    "#         if (datetime.datetime.strptime(tup[0], fmt) > datetime.datetime.strptime(max_morning, fmt)):\n",
    "#             max_morning = tup[0]\n",
    "            \n",
    "#         if (datetime.datetime.strptime(tup[1], fmt) < datetime.datetime.strptime(min_night, fmt)):\n",
    "#             min_night = tup[1]\n",
    "#         if (datetime.datetime.strptime(tup[1], fmt) > datetime.datetime.strptime(max_night, fmt)):\n",
    "#             max_night = tup[1]\n",
    "        \n",
    "#     seconds = total_morning_seconds\n",
    "#     hours, seconds =  str((seconds // 3600) // len(times)).zfill(2), seconds % 3600\n",
    "#     minutes, seconds = str(seconds // 60).zfill(2), str(seconds % 60).zfill(2)\n",
    "#     average_morning = \"{}:{}:{}\".format(hours, minutes, seconds)\n",
    "    \n",
    "#     seconds = total_night_seconds\n",
    "#     hours, seconds =  str((seconds // 3600) // len(times)).zfill(2), seconds % 3600\n",
    "#     minutes, seconds = str(seconds // 60).zfill(2), str(seconds % 60).zfill(2)\n",
    "#     average_night = \"{}:{}:{}\".format(hours, minutes, seconds)\n",
    "    \n",
    "#     return { \\\n",
    "#             'min_morning': min_morning, \\\n",
    "#             'average_morning': average_morning, \\\n",
    "#             'max_morning': max_morning, \\\n",
    "#             'min_night': min_night, \\\n",
    "#             'average_night': average_night, \\\n",
    "#             'max_night': max_night \\\n",
    "#            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circadian_rythm_data = get_average_circadian_rythm_time(circadian_rythms)\n",
    "# circadian_rythm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# microwave_stovetop = {'microwave': uq49_microwave_normalised, 'stovetop': uq49_stove_normalised}\n",
    "# circadian_rythm_metrics = circadian_rythm_data\n",
    "# circadian_rythm_test = {'morning': '05:28:00', 'night': '22:21:00'}\n",
    "# data={'microwave_stovetop': microwave_stovetop, \\\n",
    "#       'circadian_rythm_metrics': circadian_rythm_metrics, \\\n",
    "#       'circadian_rythm_test': circadian_rythm_test, \\\n",
    "#      }\n",
    "\n",
    "# r = requests.post('http://localhost:3001/data', json=data)\n",
    "# print(r.json())\n",
    "# print(r.status_code, '\\n')\n",
    "# pp.pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Export data from DB to csv???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nighttime Disturbances------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add a 2 hour buffer around the circadian rhythm time\n",
    "def compareTime(first, second):\n",
    "    a = datetime.datetime.strptime(first, '%H:%M:%S')\n",
    "    b = datetime.datetime.strptime(second, '%H:%M:%S')\n",
    "    if (a < b):\n",
    "        return -1\n",
    "    elif (a > b):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spikes (Watts greater than houses resting power use)...\n",
    "# of less than 30 mins in duration between their circadian rhythm times.\n",
    "def get_sleep_disturbances(data):\n",
    "    sleep_disturbances = []\n",
    "    circadian_rythms = []\n",
    "    for household in data:\n",
    "        curr_disturbances = get_peaks(household, 5, 1000, 1, 30, 60)\n",
    "        try:\n",
    "            circadian_rhythm = get_circadian_rythm(household)\n",
    "#             print(circadian_rhythm)\n",
    "\n",
    "            curr_disturbances = [peak for peak in curr_disturbances if compareTime(peak[0][11:], circadian_rhythm[0]) < 0 \\\n",
    "                                 or compareTime(peak[0][11:], circadian_rhythm[1]) > 0]\n",
    "            sleep_disturbances.append(curr_disturbances)\n",
    "        except ZeroDivisionError:\n",
    "            sleep_disturbances.append(-1)\n",
    "#             print('div zero error')\n",
    "\n",
    "    return [len(arr) if type(arr) != int else arr for arr in sleep_disturbances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'light_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-394a1cbb78cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msleep_disturbances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sleep_disturbances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlight_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msleep_disturbances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'light_processed' is not defined"
     ]
    }
   ],
   "source": [
    "sleep_disturbances = get_sleep_disturbances(light_processed)\n",
    "sleep_disturbances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_disturbances_normalised = []\n",
    "for val in sleep_disturbances:\n",
    "    if val == -1:\n",
    "        sleep_disturbances_normalised.append(-2)\n",
    "    else:\n",
    "        sleep_disturbances_normalised.append(normalise(val, min([x for x in sleep_disturbances if x != -1]), max(sleep_disturbances)))\n",
    "sleep_disturbances_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = \"\"\"SELECT * FROM \"iotawatt\" WHERE \"device\" = 'uq49' AND \"sensor\" = 'Lights1' AND \"time\" >= '2021-03-01T00:00:00Z' AND \"time\" <= '2021-03-31T23:59:50Z'\"\"\"\n",
    "\n",
    "# uq49_light_data = pd.DataFrame(client2.query(q, chunked=True))\n",
    "# uq49_light_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uq49_light_data_processed = pre_process(uq49_light_data)\n",
    "# uq49_light_data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uq49_sleep_disturbances = get_sleep_disturbances(uq49_light_data_processed)\n",
    "# uq49_sleep_disturbances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# uq49_sleep_disturbances_normalised = normalise(uq49_sleep_disturbances[0], min(sleep_disturbances), max(sleep_disturbances))\n",
    "# uq49_sleep_disturbances_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work Schedule-------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_work_schedules(data):\n",
    "    lst = []\n",
    "    for household in data:\n",
    "        try:\n",
    "            lst.append(get_work_schedule(household))\n",
    "        except ZeroDivisionError:\n",
    "#             print(\"zero div err\")\n",
    "            lst.append(0)\n",
    "#             lst.append(('0', '0'))\n",
    "            \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_schedules = get_work_schedules(light_processed)\n",
    "work_schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hoursBetween(first, second, overnight=False):\n",
    "    a = datetime.datetime.strptime(first, '%H:%M:%S')\n",
    "    b = datetime.datetime.strptime(second, '%H:%M:%S')\n",
    "    if (overnight == True):\n",
    "        temp = b\n",
    "        b = a + datetime.timedelta(days=1)\n",
    "        a = temp\n",
    "    diff = b - a\n",
    "    return int(diff.total_seconds() // 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_work_durations(work_schedules):\n",
    "    duration = []\n",
    "    for tup in work_schedules:\n",
    "        if (tup == 0):\n",
    "            duration.append(-2)\n",
    "        else:\n",
    "            duration.append(hoursBetween(tup[0], tup[1]))\n",
    "    return duration        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_durations = get_work_durations(work_schedules)\n",
    "work_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_durations_normalised = []\n",
    "for val in work_durations:\n",
    "    if val == -2:\n",
    "        work_durations_normalised.append(-2)\n",
    "    else:\n",
    "        work_durations_normalised.append(normalise(val, min([x for x in work_durations if x != -2]), max(work_durations)))\n",
    "work_durations_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uq49_work_schedule = get_work_schedules(uq49_light_data_processed)\n",
    "# uq49_work_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uq49_work_duration = get_work_duration(uq49_work_schedule)\n",
    "# uq49_work_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uq49_work_duration_normalised = normalise(uq49_work_duration[0], min(work_durations), max(work_durations))\n",
    "# uq49_work_duration_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Microwave/Stovetop -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(microwave_peaks)\n",
    "print(stove_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microwave_normalised = []\n",
    "for val in microwave_peaks:\n",
    "    microwave_normalised.append(normalise(val, min(microwave_peaks), max(microwave_peaks)))\n",
    "microwave_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stovetop_normalised = []\n",
    "for val in stove_peaks:\n",
    "    stovetop_normalised.append(normalise(val, min(stove_peaks), max(stove_peaks)))\n",
    "stovetop_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sleep Duration ----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_schedules = get_all_circadian_rythm(light_processed)\n",
    "sleep_schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sleep_durations(sleep_schedules):\n",
    "    duration = []\n",
    "    for tup in sleep_schedules:\n",
    "        if (tup == 0):\n",
    "            duration.append(-2)\n",
    "        else:\n",
    "            duration.append(hoursBetween(tup[0], tup[1], True))\n",
    "    return duration  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_durations = get_sleep_durations(sleep_schedules)\n",
    "sleep_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_durations_normalised = []\n",
    "for val in sleep_durations:\n",
    "    if val == -2:\n",
    "        sleep_durations_normalised.append(-2)\n",
    "    else:\n",
    "        sleep_durations_normalised.append(normalise(val, min([x for x in sleep_durations if x != -2]), max(sleep_durations)))\n",
    "sleep_durations_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ages = { \n",
    "#         \"uq10\": 40,\n",
    "#         \"uq12\": 38,\n",
    "#         \"uq23\": 49,\n",
    "#         \"uq24\": 53,\n",
    "#         \"uq26\": 41,\n",
    "#         \"uq33\": 44,\n",
    "#         \"uq37\": 65,\n",
    "#         \"uq45\": 40,\n",
    "#         \"uq48\": 55,\n",
    "#         \"uq49\": 27,\n",
    "#         \"uq56\": 52,\n",
    "#         \"uq57\": 65,\n",
    "#         \"uq61\": 56,\n",
    "#         \"uq67\": 47, \n",
    "#         \"uq68\": 50,\n",
    "#         \"uq75\": 30,\n",
    "#         \"uq85\": 38,\n",
    "#         \"uq88\": 55,\n",
    "#         \"uq92\": 33,\n",
    "#         \"hfs01a\": 35,\n",
    "#         \"hfs02a\": 45        \n",
    "#        }\n",
    "ages = { \n",
    "        \"uq10\": 40,\n",
    "        \"uq12\": 38,\n",
    "        \"uq23\": 49,\n",
    "        \"uq24\": 53,\n",
    "        \"uq26\": 41,\n",
    "        \"hfs01a\": 35,\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ages():\n",
    "    return ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANKING ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in the variables of measuring stress/anxiety [-1,1] and returns a between [0,100] to be displayed\n",
    "def stress_anxiety(sleep_disturbances, work_durations, sleep_durations, microwave, stovetop, ages, consumptions):\n",
    "    print(\"Sleep Disturbances: \\t\", sleep_disturbances)\n",
    "    print(\"Work Durations: \\t\", work_durations)\n",
    "    print(\"Sleep Durations: \\t\", sleep_durations)\n",
    "    print(\"Microwave: \\t\\t\", microwave)\n",
    "    print(\"Stovetop: \\t\\t\", stovetop)\n",
    "    print(\"Ages: \\t\\t\", ages)\n",
    "    print(\"Consumption: \\t\", consumption)\n",
    "    \n",
    "    ranks = [0] * 6\n",
    "    for i, sleep_disturbance in enumerate(sleep_disturbances):\n",
    "        if sleep_disturbance != -2: \n",
    "            if (sleep_disturbance > 0.6):\n",
    "                ranks[i] += 2\n",
    "            elif (sleep_disturbance > 0.2):\n",
    "                ranks[i] += 1\n",
    "    for i, work_duration in enumerate(work_durations):\n",
    "        if work_duration != -2:\n",
    "            if (work_duration > 0.6):\n",
    "                ranks[i] += 2\n",
    "            elif (work_duration > 0.2):\n",
    "                ranks[i] += 1\n",
    "    for i, sleep_duration in enumerate(sleep_durations):\n",
    "        if sleep_duration != -2:\n",
    "            if (sleep_duration < 0.6):\n",
    "                ranks[i] += 2\n",
    "            elif (sleep_duration < 0.2):\n",
    "                ranks[i] += 1\n",
    "    for i in range(len(microwave)):\n",
    "        if (microwave[i] > 0.4 and stovetop[i] < -0.4):\n",
    "            ranks[i] += 2\n",
    "        elif (microwave[i] > 0.2 and stovetop[i] < -0.2):\n",
    "            ranks[i] += 1\n",
    "    for i, age in enumerate(ages.values()):\n",
    "        if age >= 65:\n",
    "            ranks[i] -= 2\n",
    "    for i, consumption in enumerate(consumptions):\n",
    "        if consumption != -2:\n",
    "            if (consumption < 0.6):\n",
    "                ranks[i] += 2\n",
    "            elif (consumption < 0.2):\n",
    "                ranks[i] += 1\n",
    "            \n",
    "    for rank in ranks:\n",
    "        if (rank < 0):\n",
    "            rank = 0\n",
    "    \n",
    "    print(\"Ranks: \\t\\t\\t\", ranks)\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a ranked value between 0 and 100\n",
    "# Got this wrong. Should take in a bunch of [-1,1] values are return a [0,100] value for the entire subject\n",
    "def rank(oldValue):\n",
    "    oldMin = -1\n",
    "    oldMax = 1 \n",
    "    newMin = 0\n",
    "    newMax = 100 # The scale we want to show in the visualisations\n",
    "    \n",
    "    oldRange = (oldMax - oldMin)  \n",
    "    newRange = (newMax - newMin)  \n",
    "    newValue = (((oldValue - oldMin) * newRange) / oldRange) + newMin\n",
    "    \n",
    "    return int(newValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uq49_sleep_disturbances_ranked = rank(uq49_sleep_disturbances_normalised)\n",
    "# uq49_sleep_disturbances_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uq49_work_duration_ranked = rank(uq49_work_duration_normalised)\n",
    "# uq49_work_duration_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stress_anxiety = stress_anxiety(uq49_sleep_disturbances_normalised, uq49_work_duration_normalised)\n",
    "# stress_anxiety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the stress/anxiety indexes of the 6 households that data was queried from.\n",
    "# TODO: Extract more data (depth and breadth) and apply the same process to extract more meaningful values.\n",
    "# TODO: Then, turn the ranks into a normalised value (with respect to the other households) between [0,100]\n",
    "stress_anxiety_all = stress_anxiety(sleep_disturbances_normalised, work_durations_normalised, sleep_durations_normalised, microwave_normalised, stovetop_normalised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final normalisation and ranking with respect to other households in dataset\n",
    "# Displays key, value pairs == 'household': rank\n",
    "def normalise_and_rank(ranks, names):\n",
    "    values = {}\n",
    "    for i in range(len(ranks)):\n",
    "        normalised = normalise(ranks[i], min(ranks), max(ranks))\n",
    "        ranked = rank(normalised)\n",
    "        values[names[i]] = ranked\n",
    "    print(\"Values: \", values)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = normalise_and_rank(stress_anxiety_all, list(light_circuits.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def something():\n",
    "    months = ['2020-10-01', '2020-11-01', '2020-12-01']     #, '2021-01-01', '2021-02-01', '2021-03-01']\n",
    "    \n",
    "    final_result = {}\n",
    "    \n",
    "    for j in range(len(months)-1):\n",
    "        print(\"--- Processing {} => {} ---\".format(months[j], months[j+1]))\n",
    "        \n",
    "        # Microwave Data\n",
    "        print(\"Getting microwave data\")\n",
    "        microwave_dataframes = []\n",
    "        for i, home in enumerate(power_circuits):\n",
    "            microwave_dataframes.append(get_data_in_period(client2, \"'{}T00:00:00Z'\".format(months[j]), \"'{}T00:00:00Z'\".format(months[j+1]), \"'{}'\".format(home), \"'{}'\".format(power_circuits[home])))\n",
    "        \n",
    "        # Stove Data\n",
    "        print(\"Getting stove data\")\n",
    "        stove_dataframes = []\n",
    "        for i, home in enumerate(stove_circuits):\n",
    "            stove_dataframes.append(get_data_in_period(client2, \"'{}T00:00:00Z'\".format(months[j]), \"'{}T00:00:00Z'\".format(months[j+1]), \"'{}'\".format(home), \"'{}'\".format(stove_circuits[home])))           \n",
    "        \n",
    "        # Preprocessing \n",
    "        print(\"Processing microwave data\")\n",
    "        microwave_processed = pre_process(microwave_dataframes)\n",
    "        print(\"Processing stove data\")\n",
    "        stove_processed = pre_process(stove_dataframes)\n",
    "        \n",
    "        \n",
    "        # 1. Microwave vs Stovetop Use\n",
    "        print(\"1. Calculating microwave vs stovetop use\")\n",
    "        microwave_peaks, stove_peaks = microwave_stove_peaks(microwave_processed, stove_processed)\n",
    "        \n",
    "        microwave_normalised = []\n",
    "        for val in microwave_peaks:\n",
    "            microwave_normalised.append(normalise(val, min(microwave_peaks), max(microwave_peaks)))\n",
    "            \n",
    "        stovetop_normalised = []\n",
    "        for val in stove_peaks:\n",
    "            stovetop_normalised.append(normalise(val, min(stove_peaks), max(stove_peaks)))\n",
    "           \n",
    "        \n",
    "        # Light Data\n",
    "        print(\"Getting lights data\")\n",
    "        light_dataframes = []\n",
    "        for i, home in enumerate(light_circuits):\n",
    "            light_dataframes.append(get_data_in_period(client2, \"'{}T00:00:00Z'\".format(months[j]), \"'{}T00:00:00Z'\".format(months[j+1]), \"'{}'\".format(home), \"'{}'\".format(light_circuits[home])))\n",
    "        \n",
    "        # Preprocessing\n",
    "        print(\"Processing lights data\")\n",
    "        light_processed = pre_process(light_dataframes)\n",
    "        \n",
    "        \n",
    "        # 2. Sleep Disturbance\n",
    "        print(\"2. Calculating sleep disturbance\")\n",
    "        sleep_disturbances = get_sleep_disturbances(light_processed)\n",
    "        \n",
    "        sleep_disturbances_normalised = []\n",
    "        for val in sleep_disturbances:\n",
    "            if val == -1:\n",
    "                sleep_disturbances_normalised.append(-2)\n",
    "            else:\n",
    "                sleep_disturbances_normalised.append(normalise(val, min([x for x in sleep_disturbances if x != -1]), max(sleep_disturbances)))\n",
    "\n",
    "                \n",
    "        # 3. Work Duration\n",
    "        print(\"3. Calculating work duration\")\n",
    "        work_schedules = get_work_schedules(light_processed)\n",
    "        \n",
    "        work_durations = get_work_durations(work_schedules)\n",
    "        \n",
    "        work_durations_normalised = []\n",
    "        for val in work_durations:\n",
    "            if val == -2:\n",
    "                work_durations_normalised.append(-2)\n",
    "            else:\n",
    "                work_durations_normalised.append(normalise(val, min([x for x in work_durations if x != -2]), max(work_durations)))\n",
    "        \n",
    "        \n",
    "        # 4. Sleep Duration\n",
    "        print(\"4. Calculating sleep duration\")\n",
    "        sleep_schedules = get_all_circadian_rythm(light_processed)\n",
    "\n",
    "        sleep_durations = get_sleep_durations(sleep_schedules)\n",
    "        \n",
    "        sleep_durations_normalised = []\n",
    "        for val in sleep_durations:\n",
    "            if val == -2:\n",
    "                sleep_durations_normalised.append(-2)\n",
    "            else:\n",
    "                sleep_durations_normalised.append(normalise(val, min([x for x in sleep_durations if x != -2]), max(sleep_durations)))\n",
    "        \n",
    "        # 5. Age\n",
    "        print(\"5. Assessing age\")\n",
    "        ages = get_ages()\n",
    "        \n",
    "        # Consumption Data\n",
    "        print(\"Getting consumption data\")\n",
    "        consumption_dataframes = []\n",
    "        for i, home in enumerate(power_circuits):\n",
    "            consumption_dataframes.append(get_data_in_period(client2, \"'2021-03-01T00:00:00Z'\", \"'2021-03-31T23:59:50Z'\", \"'{}'\".format(home), \"'Consumption'\"))\n",
    "        \n",
    "        # Preprocessing\n",
    "        print(\"Processing consumption data\")\n",
    "        consumption_processed = pre_process(consumption_dataframes)\n",
    "        \n",
    "        # 6. Occupancy\n",
    "        print(\"6. Calculating occupancy\")\n",
    "        consumptions = get_all_consumptions(consumption_processed)\n",
    "        \n",
    "        consumption_normalised = []\n",
    "        for val in consumptions:\n",
    "            if val == -2:\n",
    "                consumption_normalised.append(-2)\n",
    "            else:\n",
    "                consumption_normalised.append(normalise(val, min([x for x in consumptions if x != -2]), max(consumptions)))\n",
    "        \n",
    "        # Ranking\n",
    "        print(\"Ranking results...\")\n",
    "        stress_anxiety_all = stress_anxiety(sleep_disturbances_normalised, work_durations_normalised, sleep_durations_normalised, microwave_normalised, stovetop_normalised, ages, consumption_normalised)\n",
    "        \n",
    "        result = normalise_and_rank(stress_anxiety_all, list(light_circuits.keys()))\n",
    "        \n",
    "        for key in list(result.keys()):\n",
    "            try:\n",
    "                final_result[key] = final_result[key] + result[key]\n",
    "            except KeyError:\n",
    "                final_result[key] = result[key]\n",
    "        print(\"Current result: \", final_result)\n",
    "        print()\n",
    "    \n",
    "    for key in list(final_result.keys()):\n",
    "        final_result[key] = final_result[key] // 2\n",
    "    \n",
    "    print(\"--- Final result ---\\n\", final_result)        \n",
    "    return final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing 2020-10-01 => 2020-11-01 ---\n",
      "Getting consumption data\n",
      "Processing consumption data\n",
      "6. Calculating occupancy\n",
      "[-0.55, -0.4, 0.31, 1.0, -0.02, -1.0]\n",
      "Ranking results...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sleep_disturbances_normalised' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-a87ec654c72c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msomething\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-44318dcbc03b>\u001b[0m in \u001b[0;36msomething\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# Ranking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ranking results...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mstress_anxiety_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstress_anxiety\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep_disturbances_normalised\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwork_durations_normalised\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msleep_durations_normalised\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmicrowave_normalised\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstovetop_normalised\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumption_normalised\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalise_and_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstress_anxiety_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlight_circuits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sleep_disturbances_normalised' is not defined"
     ]
    }
   ],
   "source": [
    "res = something()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'uq10': 100, 'uq12': 16, 'uq23': 70, 'uq24': 45, 'uq26': 16, 'hfs01a': 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption_dataframes = []\n",
    "for i, home in enumerate(power_circuits):\n",
    "    consumption_dataframes.append(get_data_in_period(client2, \"'2021-03-01T00:00:00Z'\", \"'2021-03-31T23:59:50Z'\", \"'{}'\".format(home), \"'Consumption'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consumption(data):\n",
    "    total = 0\n",
    "    for val in data:\n",
    "        total += val\n",
    "    return int(total / len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[time\n",
       " 2021-03-01 00:00:00    487\n",
       " 2021-03-01 00:00:10    489\n",
       " 2021-03-01 00:00:20    487\n",
       " 2021-03-01 00:00:30    502\n",
       " 2021-03-01 00:00:40    498\n",
       "                       ... \n",
       " 2021-03-31 23:59:10    302\n",
       " 2021-03-31 23:59:20    295\n",
       " 2021-03-31 23:59:30    296\n",
       " 2021-03-31 23:59:40    307\n",
       " 2021-03-31 23:59:50    304\n",
       " Length: 275489, dtype: int64,\n",
       " time\n",
       " 2021-03-01 00:00:00    248\n",
       " 2021-03-01 00:00:10    249\n",
       " 2021-03-01 00:00:20    250\n",
       " 2021-03-01 00:00:30    248\n",
       " 2021-03-01 00:00:40    248\n",
       "                       ... \n",
       " 2021-03-31 23:59:10    170\n",
       " 2021-03-31 23:59:20    192\n",
       " 2021-03-31 23:59:30    139\n",
       " 2021-03-31 23:59:40    187\n",
       " 2021-03-31 23:59:50    223\n",
       " Length: 275681, dtype: int64,\n",
       " time\n",
       " 2021-03-01 00:00:00     603\n",
       " 2021-03-01 00:00:10     604\n",
       " 2021-03-01 00:00:20     602\n",
       " 2021-03-01 00:00:30     601\n",
       " 2021-03-01 00:00:40     611\n",
       "                        ... \n",
       " 2021-03-31 23:59:10    3432\n",
       " 2021-03-31 23:59:20    3033\n",
       " 2021-03-31 23:59:30    3033\n",
       " 2021-03-31 23:59:40    3040\n",
       " 2021-03-31 23:59:50    3030\n",
       " Length: 275627, dtype: int64,\n",
       " time\n",
       " 2021-03-01 00:00:00    409\n",
       " 2021-03-01 00:00:10    370\n",
       " 2021-03-01 00:00:20    385\n",
       " 2021-03-01 00:00:30    392\n",
       " 2021-03-01 00:00:40    391\n",
       "                       ... \n",
       " 2021-03-31 23:59:10    503\n",
       " 2021-03-31 23:59:20    496\n",
       " 2021-03-31 23:59:30    489\n",
       " 2021-03-31 23:59:40    483\n",
       " 2021-03-31 23:59:50    470\n",
       " Length: 275641, dtype: int64,\n",
       " time\n",
       " 2021-03-01 00:00:00     689\n",
       " 2021-03-01 00:00:10     687\n",
       " 2021-03-01 00:00:20     688\n",
       " 2021-03-01 00:00:30     685\n",
       " 2021-03-01 00:00:40    1273\n",
       "                        ... \n",
       " 2021-03-31 23:59:10    2472\n",
       " 2021-03-31 23:59:20    2460\n",
       " 2021-03-31 23:59:30    2463\n",
       " 2021-03-31 23:59:40    2464\n",
       " 2021-03-31 23:59:50    2470\n",
       " Length: 275617, dtype: int64,\n",
       " time\n",
       " 2021-03-01 00:00:00    300\n",
       " 2021-03-01 00:00:05    299\n",
       " 2021-03-01 00:00:10    300\n",
       " 2021-03-01 00:00:15    298\n",
       " 2021-03-01 00:00:20    300\n",
       "                       ... \n",
       " 2021-03-31 23:59:30    303\n",
       " 2021-03-31 23:59:35    291\n",
       " 2021-03-31 23:59:40    209\n",
       " 2021-03-31 23:59:45    346\n",
       " 2021-03-31 23:59:50    317\n",
       " Length: 541351, dtype: int64]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumption_processed = pre_process(consumption_dataframes)\n",
    "consumption_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_consumptions(data):\n",
    "    consumptions = []\n",
    "    for household in data:\n",
    "        consumptions.append(get_consumption(household))\n",
    "    return consumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[480, 532, 768, 1001, 659, 329]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumptions = get_all_consumptions(consumption_processed)\n",
    "consumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.55, -0.4, 0.31, 1.0, -0.02, -1.0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumption_normalised = []\n",
    "for val in consumptions:\n",
    "    if val == -2:\n",
    "        consumption_normalised.append(-2)\n",
    "    else:\n",
    "        consumption_normalised.append(normalise(val, min([x for x in consumptions if x != -2]), max(consumptions)))\n",
    "consumption_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
